{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZSoU3F7sP3o"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "th3m5zenzcfH"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.base import clone\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import keras, tensorflow\n",
        "from keras import Sequential, metrics, callbacks, layers, losses\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical, image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byb46MiJvrrJ"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OTqWJaF1_NAY"
      },
      "outputs": [],
      "source": [
        "img_size = (256,256)\n",
        "channels = 3\n",
        "img_shape = (img_size[0],img_size[1],channels)\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_YL6rFSvzbl",
        "outputId": "fca8ba0c-57e2-4047-ad3d-ef8401ea612c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3544 files belonging to 4 classes.\n",
            "Using 3190 files for training.\n",
            "Using 354 files for validation.\n"
          ]
        }
      ],
      "source": [
        "train_set, val_set = image_dataset_from_directory(\"/content/drive/MyDrive/Colab Notebooks/Glomerulos/train\",\n",
        "                                        validation_split=0.1,\n",
        "                                        subset='both',\n",
        "                                        image_size=img_size,\n",
        "                                        batch_size=batch_size,\n",
        "                                        label_mode='categorical',\n",
        "                                        seed=2023\n",
        "                                         )\n",
        "# train_set.batch(batch_size)\n",
        "# val_set.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sjrl7zFA7DfL"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "  #layers.Normalization(),\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "  layers.RandomContrast(0.2),\n",
        "  layers.RandomBrightness(0.2),\n",
        "])\n",
        "data_augmentation.build(img_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0tNjYKq9Foj"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VirjSuC49FX6",
        "outputId": "d6e3c621-b5b3-4d3a-c99d-f5c222258d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 256, 3)            0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (64, 128, 128, 1)         76        \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (64, 64, 64, 1)           10        \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (64, 32, 32, 1)           10        \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (64, 1024)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (64, 256)                 262400    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (64, 256)                 1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (64, 256)                 0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (64, 64)                  16448     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (64, 64)                  0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (64, 4)                   260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 280228 (1.07 MB)\n",
            "Trainable params: 279716 (1.07 MB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential()\n",
        "# Augmentation\n",
        "model.add(data_augmentation)\n",
        "\n",
        "# Backbone\n",
        "model.add(layers.Conv2D(filters=1,kernel_size=5,strides=(2,2),padding=\"same\",activation=\"relu\",input_shape=img_shape))\n",
        "model.add(layers.Conv2D(filters=1,kernel_size=3,strides=(2,2),padding=\"same\",activation=\"relu\",input_shape=(img_shape[0]/2,img_shape[1]/2)))\n",
        "model.add(layers.Conv2D(filters=1,kernel_size=3,strides=(2,2),padding=\"same\",activation=\"relu\",input_shape=(img_shape[0]/4,img_shape[1]/4)))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# FCs\n",
        "model.add(layers.Dense(256,activation=('relu'),input_dim=1024))\n",
        "model.add(layers.BatchNormalization(synchronized=True))\n",
        "model.add(layers.Dropout(.3))\n",
        "model.add(layers.Dense(64,activation=('relu')))\n",
        "model.add(layers.Dropout(.2))\n",
        "model.add(layers.Dense(4,activation=('softmax')))\n",
        "\n",
        "model.build((batch_size,img_size[0],img_size[1],3))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKjX2Yx3vz9V"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C65V8IWyDXws"
      },
      "outputs": [],
      "source": [
        "epochs=50\n",
        "learn_rate=.001\n",
        "train_metrics = [metrics.CategoricalAccuracy(), metrics.F1Score()]\n",
        "checkpoint = callbacks.ModelCheckpoint(\"/content/drive/MyDrive/Colab Notebooks/best_model\",\n",
        "                             monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='auto')\n",
        "\n",
        "early = callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "train_callbacks = [callbacks.History(), checkpoint, early]\n",
        "\n",
        "model.compile(loss=losses.CategoricalCrossentropy(),\n",
        "              optimizer=Adam(learning_rate=learn_rate),\n",
        "              metrics=train_metrics\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw7iMyOnv2uB",
        "outputId": "865850c9-c0e9-43ea-bc37-c03f5b9a6ee0"
      },
      "outputs": [],
      "source": [
        "history=model.fit(\n",
        "    train_set,\n",
        "    epochs=epochs,\n",
        "    shuffle=True,\n",
        "    validation_data=val_set,\n",
        "    verbose=1,\n",
        "    callbacks=train_callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R16ROm2RNPJZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
